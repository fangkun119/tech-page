---
title: Redis参考04：缓存设计与最佳实践
author: fangkun119
date: 2025-05-11 12:00:00 +0800
categories: [中间件, Redis]
tags: [Redis]
pin: false
math: true
mermaid: true
image:
  path: /imgs/cover/redis.jpeg
  lqip: data:image/webp;base64,UklGRpoAAABXRUJQVlA4WAoAAAAQAAAADwAABwAAQUxQSDIAAAARL0AmbZurmr57yyIiqE8oiG0bejIYEQTgqiDA9vqnsUSI6H+oAERp2HZ65qP/VIAWAFZQOCBCAAAA8AEAnQEqEAAIAAVAfCWkAALp8sF8rgRgAP7o9FDvMCkMde9PK7euH5M1m6VWoDXf2FkP3BqV0ZYbO6NA/VFIAAAA
  alt: Responsive rendering of Chirpy theme on multiple devices.
---

{: .no_toc }

<details close markdown="block">
  <summary>
    目录
  </summary>
  {: .text-delta }
- TOC
{:toc}
</details>
## 1 介绍

使用 Redis 缓存，会遇到如下问题，本文详细介绍这些问题和解决办法，下表是简要概括

|                        | 原因                                         | 解决办法                                             |
| ---------------------- | -------------------------------------------- | ---------------------------------------------------- |
| 缓存失效               | 大批量 Key 同时失效                          | 1. 给过期时间加上随机数，避免它们同时失效            |
| 缓存穿透               | 大量查询指向不存在的 key                     | 1. 缓存空对象，加短超时短续期；2. 布隆过滤器         |
| 突发热点问题           | 大量突发请求引发高并发缓存构建               | 1. 双重检测锁                                        |
| 缓存与数据库数据不一致 | 高并读写或双写时，缓存与数据库数据数据不一致 | 1. 分布式读写锁                                      |
| 缓存雪崩               | 缓存无法承载流量，引发后台数据库性能崩溃     | 1. 高可用缓存；2. 分级限流；3. 演练；4. 专用热点缓存 |

## 2 缓存失效（击穿）

### 2.1 什么是缓存失效

大批量缓存在同一时间失效，导致大量请求同时穿透缓存直达数据库，造成数据库瞬间压力过大甚至挂掉。

例如：

* 双 11 大促销，很多店家批量上货
* 这些商品在缓存预热时被同时加入到缓存中，如果过期时间也相同，那么他们就可能会同时失效

### 2.2 解决办法：过期时间加随机数

将这一批数据的缓存过期时间设置为一个时间段内的不同时间。

示例代码

```java
String get(String key) {
    // 从缓存中获取数据
    String cacheValue = cache.get(key);
    // 缓存为空
    if (StringUtils.isBlank(cacheValue)) {
        // 从存储中获取
        String storageValue = storage.get(key);
        cache.set(key, storageValue);
        // 设置一个过期时间(300 到 600 之间的一个随机数)
        int expireTime = new Random().nextInt(300) + 300;
        if (storageValue == null) {
            cache.expire(key, expireTime);
        }
        return storageValue;
    } else {
        // 缓存非空
        return cacheValue;
    }
}
```

## 3 缓存穿透

### 3.1 缓存穿透是什么

缓存穿透是指查询一个根本不存在的数据：

* 缓存层和存储层都不会命中：通常出于容错的考虑，如果从存储层查不到数据则不写入缓存层，下次查询依然会穿透到数据库。
* 缓存穿透将导致不存在的数据每次请求都要到存储层去查询：失去了缓存保护后端存储的意义。

造成缓存穿透的基本原因有两个：

* 自身业务代码或者数据出现问题。
* 一些恶意攻击、爬虫等造成大量空命中。
* 一个热门商品突然被删除了，但是请求还是源源不断。

### 3.2 解决方法 1：缓存空对象

#### (1) 要点

* 如果缓存拿到的是空对象，就向前端返回 null（或者其他告诉前端库存不存在的约定响应），以便让前端能够识别出来这是查不到数据
* 写入的空对象，要有一个较短的超时时间，避免黑客不断更换各种不同的 Key 来尝试，把缓存空间耗尽
* 读到空对象时，加一个较短的随机续期，避免黑客或用户持续用一批相同的 Key 请求，而这批 Key 突然同时批量

#### (2) 代码示例

```java
private Product getProductFromCache(String productCacheKey) {
    // 返回值
    Product product = null;
  	// 从缓存中获取数据
    String productStr = redisUtil.get(productCacheKey);
    // 从缓存中取到数据
    if (!StringUtils.isEmpty(productStr)) {
        // 如果是空对象、给它增加一个较短随机续期
        if (EMPTY_CACHE.equals(productStr)) {
            redisUtil.expire(productCacheKey, genEmptyCacheTimeout(), TimeUnit.SECONDS);
            return new Product();
        }
      	// 如果是正常对象、给它增加普通的随机续期
        product = JSON.parseObject(productStr, Product.class);
        redisUtil.expire(productCacheKey, genProductCacheTimeout(), TimeUnit.SECONDS); //读延期
    } else {
      	// 如果缓存 miss，参考第 4.3 小节（突发热点问题，示例代码中 2.2 部分，缓存空对象）
        ; 
    }
    return product;
}

private Integer genProductCacheTimeout() {
    return PRODUCT_CACHE_TIMEOUT + new Random().nextInt(5) * 60 * 60;
}

private Integer genEmptyCacheTimeout() {
    return 60 + new Random().nextInt(30);
}
```

### 3.3 解决方法 2：布隆过滤器

#### (1) 介绍

对于恶意攻击场景（向服务器请求大量不存在的数据造成的缓存穿透），可以用布隆过滤器先做一次过滤。

* 适用于数据命中不高、数据相对固定、实时性低（通常是数据集较大）的应用场景。
* 优点：缓存空间占用很少。
* 缺点：(1) 不支持删除，也就是说它存储的是“插入过”的数据；(2) 代码维护较为复杂。

布隆过滤器

* 一个大型的位数组和几个不一样的无偏hash 函数（ 无偏：能够把元素的 hash 值算得比较均匀）。
* 添加 key 时，用这些无偏 hash 计算出几个不同的数组下标，将这些下标位置全部设置为 1。
* 查询 key 时，用这些无偏 hash 计算出几个不同的数组下标，所有位置都为 1 代表 key 存在。

布隆过滤器的特点：

* 当过滤器显示某个 Key 存在时，这个 Key 可能不存在（Hash 函数计算出的位置被置为 1， 可能是因为其它的 key 存在所致）。可以通过增大数组长度，来降低这个误判的概率。
* 但是当过滤器显示这个 Key 不存在，那么它一定不存在

#### (2) 代码示例

可以用 redisson 实现布隆过滤器（它封装了 BloomFilter），引入依赖

```xml
<dependency>
   <groupId>org.redisson</groupId>
   <artifactId>redisson</artifactId>
   <version>3.6.5</version>
</dependency>
```

示例代码：

```java
package com.redisson;

import org.redisson.Redisson;
import org.redisson.api.RBloomFilter;
import org.redisson.api.RedissonClient;
import org.redisson.config.Config;

public class RedissonBloomFilter {
    public static void main(String[] args) {
        Config config = new Config();
        config.useSingleServer().setAddress("redis://localhost:6379");
        // 构造 Redisson
        RedissonClient redisson = Redisson.create(config);

        RBloomFilter<String> bloomFilter = redisson.getBloomFilter("nameList");
        // 初始化布隆过滤器：预计元素为 100000000L，误差率为 3%，根据这两个参数会计算出底层的 bit 数组大小
        bloomFilter.tryInit(100000000L, 0.03);

        // 将 zhuge 插入到布隆过滤器中
        bloomFilter.add("zhuge");

        // 判断下面号码是否在布隆过滤器中
        System.out.println(bloomFilter.contains("guojia")); // false
        System.out.println(bloomFilter.contains("baiqi")); // false
        System.out.println(bloomFilter.contains("zhuge")); // true
    }
}
```

使用布隆过滤器需要把所有数据提前放入布隆过滤器，并且在增加数据时也要往布隆过滤器里放，布隆过滤器缓存过滤伪代码：

```java
// 初始化布隆过滤器
RBloomFilter<String> bloomFilter = redisson.getBloomFilter("nameList");
// 初始化布隆过滤器：预计元素为 100000000L，误差率为 3%
bloomFilter.tryInit(100000000L, 0.03);

void init() {
    for (String key : keys) {
        bloomFilter.put(key);
    }
}

String get(String key) {
    // 从布隆过滤器这一级缓存判断下 key 是否存在
    Boolean exist = bloomFilter.contains(key);
    if (!exist) {
        return "";
    }
    // 从缓存中获取数据
    String cacheValue = cache.get(key);
    // 缓存为空
    if (StringUtils.isBlank(cacheValue)) {
        // 从存储中获取
        String storageValue = storage.get(key);
        cache.set(key, storageValue);
        // 如果存储数据为空，需要设置一个过期时间(300秒)
        if (storageValue == null) {
            cache.expire(key, 60 * 5);
        }
        return storageValue;
    } else {
        // 缓存非空
        return cacheValue;
    }
}
```

注意：布隆过滤器不能删除数据，如果要删除得重新初始化数据。

## 4 突发热点问题

### 4.1  大量突发请求引发高并发缓存构建

发生场景

* 冷门商品突然变热门商品，例如热点事件、大 V 直播带货等
* 同一时刻几十万请求，突然查询同一个冷门商品，因为该商品并没有被缓存，因此会引发高并发数据库查询

### 4.2 解决办法：双重检测锁

解决这个问题的关键是避免并发重建缓存

步骤如下

1. 第一重检测：检测缓存是否有这个 key
2. 加锁
3. 第二重检测：检测缓存是否已经其它线程被重建
4. 如果没有，则开始重建缓存

### 4.3 示例代码

```java
public Product get(Long productId) throws InterruptedException {
    // 变量
    Product product = null;
    String productCacheKey = RedisKeyPrefixConst.PRODUCT_CACHE + productId; // 缓存 Key：前缀 + product_id

    // 步骤 1：第一重检查、查看 Key 是否在缓存中
    product = getProductFromCache(productCacheKey);
    if (product != null) {
        // 如果缓存命中则直接返回，不需要构建缓存
        return product;
    }

    // 步骤 2：获取缓存锁（如果很多请求瞬间高并发，一重检查都没查到 key，那么他们都会挤在这里等待获取锁）
    RLock hotCacheLock = redisson.getLock(LOCK_PRODUCT_HOT_CACHE_PREFIX + productId);
    hotCacheLock.lock(); // 用 tryLock 可以减少阻塞，但是有把请求漏到数据库的风险
    try {
        // 步骤 3：第二重检查、查看缓存是否已经被其它线程创建
        product = getProductFromCache(productCacheKey);
        if (product != null) {
            // 如果缓存命中则直接返回，不需要构建缓存
            return product;
        }

        // 步骤 4：读取数据库并构建缓存
        // 1 获取数据锁（读锁），这把锁是为了避免一下小节读写不一致而设置的，因为这里是读数据所以用的是读锁
        RReadWriteLock readWriteLock = redisson.getReadWriteLock(LOCK_PRODUCT_UPDATE_PREFIX + productId);
        RLock rLock = readWriteLock.readLock();
        rLock.lock();
        try {
            // 2 读数据库
            product = productDao.get(productId);
            if (product != null) {
                // 2.1 如果商品存在，从数据库读取并构建缓存
                // 写入到 Redis 缓存，并设置失效时间（为了防止批量同时失效，失效时间加了随机数）
                redisUtil.set(productCacheKey, JSON.toJSONString(product), genProductCacheTimeout(), TimeUnit.SECONDS);
            } else {
                // 2.2 如果商品不存在，向 Redis 设置空缓存
                redisUtil.set(productCacheKey, EMPTY_CACHE, genEmptyCacheTimeout(), TimeUnit.SECONDS);
            }
        } finally {
            // 3 解锁 update 锁
            rLock.unlock();
        }
    } finally {
        // 步骤 5：解锁缓存锁
        hotCacheLock.unlock();
    }
    return product;
}
```

## 5 缓存与数据库不一致问题

### 5.1 三种不一致

在大并发下，同时操作数据库与缓存会产生两种不一致问题

#### (1) 读写不一致：写数据库后更新缓存

读线程触发了缓存加载，用读到的旧数据覆盖了写线程写入的新数据

例如下面的操作顺序，线程 1 是读线程，线程 2 是写线程

```text
线程 1 缓存 miss -> 线程 1 读数据库 -> 线程 2 写数据库 -> 线程 2 写缓存 -> 线程 1 写缓存
```

操作完成后

```text
数据库：线程 2 写入的新数据
缓存：线程 1 写入的旧数据
```

#### (2) 读写不一致：写数据库后删除缓存

这个策略假设读操作发生在写线程删除缓存之后，但实际上，读操作并非原子的，可以被分成两段跨在写操作之前和之后。

具体就是：

* 读线程读数据库：发生在写线程之前，读到了旧数据
* 读线程写缓存：发生在写线程之后，用旧数据覆盖了写线程写入的新数据

例如下面的操作顺序，线程 2 是读线程，线程 3 是写线程

```text
线程 1 通过写数据库触发缓存删除 -> 线程 2 缓存 miss 触发读数据库 -> 线程 3 写数据库 -> 线程 3 删除缓存 -> 线程 2 用读到的旧数据更新缓存
```

操作完成后

```text
数据库：线程 3 写入的新数据
缓存：线程 2 写入的旧数据
```

#### (3) 双写不一致

两个写线程同时写，数据库和缓存的数据不一致

例如下面的操作顺序：

```text
线程 1 写数据库 -> 线程 2 写数据库 -> 线程 2 更新缓存 -> 线程 1 更新缓存
```

操作完成后

```text
数据库：线程 2 写入的数据
缓存：线程 1 写入的数据
```

### 5.2 解决方法

#### (1) 能容忍的情况下用“过期时间”

**并发几率很小的数据**

* 如个人维度的订单数据、用户数据等，不会有很多人用同一个账号同时访问。
* 这种几乎不用考虑这个问题，很少会发生缓存不一致。
* 给缓存数据加上过期时间进行兜底，每隔一段时间触发读的主动更新即可。

**并发很高的数据，如果业务上能容忍短时间的缓存数据不一致**

* 如商品名称，商品分类菜单等。
* 缓存加上过期时间依然可以解决大部分业务对于缓存的要求。

#### (2) 不能容忍，且读多写少

方法 1：通过加分布式读写锁保证并发读写或写写的时候按顺序排好队，读读的时候相当于无锁。

方法 2：用阿里开源的 canal 通过监听数据库的 binlog 日志及时的去修改缓存，但是引入了新的中间件，增加了系统的复杂度。

示例代码（读线程）：见上一小节“突发热点问题”

示例代码（写线程 - 添加数据，更新数据）

```java
public Product create(Product product) {
    // 加写锁
    RReadWriteLock readWriteLock = redisson.getReadWriteLock(LOCK_PRODUCT_UPDATE_PREFIX + product.getId());
    RLock writeLock = readWriteLock.writeLock();
    writeLock.lock();
    try {
        // 写入数据库
        Product productResult = productDao.create(product);
        // 写入缓存
        redisUtil.set(RedisKeyPrefixConst.PRODUCT_CACHE + productResult.getId(), JSON.toJSONString(productResult),
                genProductCacheTimeout(), TimeUnit.SECONDS);
        // 返回结果
        return productResult;
    } finally {
        writeLock.unlock();
    }
}

public Product update(Product product) {
    // 加写锁
    RReadWriteLock readWriteLock = redisson.getReadWriteLock(LOCK_PRODUCT_UPDATE_PREFIX + product.getId());
    RLock writeLock = readWriteLock.writeLock();
    writeLock.lock();
    try {
        // 更新数据库
        Product productResult = productDao.update(product);
        // 更新 Redis 缓存
        redisUtil.set(RedisKeyPrefixConst.PRODUCT_CACHE + productResult.getId(), JSON.toJSONString(productResult),
                genProductCacheTimeout(), TimeUnit.SECONDS);
        // 返回结果
        return productResult;
    } finally {
        // 解锁
        writeLock.unlock();
    }
}
```

#### (3) 不能容忍，且读多写多

* 以上我们针对的都是读多写少的情况加入缓存提高性能，如果写多读多的情况又不能容忍缓存数据不一致，那就没必要加缓存了，可以直接操作数据库
* 当然如果数据库抗不住压力，还可以把缓存作为数据读写的主存储，异步将数据同步到数据库，数据库只是作为数据的备份。

#### (4) 总结

放入缓存的数据应该是对实时性、一致性要求不是很高的数据。切记不要为了用缓存，同时又要保证绝对的一致性做大量的过度设计和控制，增加系统复杂性！

## 6 缓存雪崩

### 6.1 什么是缓存雪崩

缓存层支撑不住或宕机后，流量像雪崩一样打向后台的存储层，造成存储层也会级联宕机。

例如：

* 超大并发量，缓存层支撑不住。
* 缓存设计不好，类似大量请求访问 bigkey，导致缓存能支撑的并发急剧下降。

### 6.2 预防和解决

从以下几个方面着手

#### (1) 缓存层服务高可用性

比如使用 Redis Sentinel 或 Redis Cluster。

#### (2) 分级限流

依赖隔离组件为后端限流熔断并降级。

* 比如使用 Sentinel 或 Hystrix 限流降级组件。
* 比如服务降级，针对不同的数据采取不同的处理方式：当业务应用访问的是非核心数据（例如电商商品属性，用户信息等）时，暂时停止从缓存中查询这些数据，而是直接返回预定义的默认降级信息、空值或是错误提示信息；当业务应用访问的是核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。

#### (3) 提前演练

在项目上线前，演练缓存层宕机场景，在此基础上做预案设定。

#### (4) 热点缓存

一个方法是使用本地内存缓存，例如在写入 Redis 缓存后，同样可以在写入本地缓存，但这样有三个问题：

* 有内存泄露风险（缓存了之后不会再用的数据 ），而实现淘汰策略又太复杂，一个办法是用 Escache 等框架来做
* 更新缓存后，并不能同步到其它 instance，如果引入 MQ 等进行通知，又太复杂

真实互联网公司的解决办法是：只有热点中的热点才有缓存雪崩的问题，为这类请求专门搭建一个热点缓存系统

* 让 Web 应用去监听
* 当收到通知时，主动切换到热点缓存系统
